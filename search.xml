<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>SAE：Rank+(预训练+GNN联合训练)</title>
      <link href="/2020/03/04/sae-yue-du/"/>
      <url>/2020/03/04/sae-yue-du/</url>
      
        <content type="html"><![CDATA[<h1 id="SAE：rank-预训练-GNN联合训练"><a href="#SAE：rank-预训练-GNN联合训练" class="headerlink" title="SAE：rank+(预训练+GNN联合训练)"></a>SAE：rank+(预训练+GNN联合训练)</h1><h2 id="论文地址"><a href="#论文地址" class="headerlink" title="论文地址"></a>论文地址</h2><p><a href="https://arxiv.org/pdf/1911.00484.pdf" target="_blank" rel="noopener">Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents</a></p><h2 id="一句话概括"><a href="#一句话概括" class="headerlink" title="一句话概括"></a>一句话概括</h2><p>首先Multi-Head Attention以Rank方式挑选问题相关文章，然后使用预训练模型得到Span信息 + GNN获取支撑句以及回答类型的联合训练的方式得到最终阅读理解的答案以及解释。</p><h2 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>构建目前阅读理解通用流程，并在各个流程中提出自己的优化方法。首先通过对比排序的方式过滤掉答案无关段落，然后通过答案预测任务和支撑句预测任务联合训练得到最终的结果。</p><h3 id="实现亮点"><a href="#实现亮点" class="headerlink" title="实现亮点"></a>实现亮点</h3><ol><li>使用Multi-Head Attention实现对段落的rank<br><img src="https://i.loli.net/2020/03/04/txmFIgXZ8S6quar.png" alt="document_selector.png"><br>rank策略是为段落设定不同的rank值，如果段落为支撑句则rank值为1，若段落包含答案则rank值为2，其余为零。在训练过程中使用句对比较使用Multi-Head Attention进行训练。然后取top k相关段落。</li><li>使用GNN得到支撑句以及答案类型<br><img src="https://i.loli.net/2020/03/04/jFKb8pgYSdMVTCq.png" alt="sup_type_gnn.png"><br>将BERT编码后的Sentence节点输入到GNN中，然后使用GCN的训练策略达到图平衡。然后对平衡后的节点接两层感知机进行支撑句预测，同时使用支撑句label+graph attention+两层感知机的方式获取答案类型</li><li>将span预测、支撑句和答案类型预测联合训练<br><img src="https://i.loli.net/2020/03/04/YDywU7eLtdIcbmp.png" alt="answer_span_sup.png"><br>以上图的方式获得答案span，然后加上上个亮点的支撑段落抽取以及答案类型判断获取联合损失进行训练。<br>$$ L = \gamma L^{span} + BCE(\hat{y}^{sp}, y^{sp}) + CE(\hat{y}^{ans}, y^{ans}) $$<h3 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h3>在HotpotQA的非开放域的数据集上实现次SOTA(截止该文章发表)<h4 id="消融实验分析"><a href="#消融实验分析" class="headerlink" title="消融实验分析"></a>消融实验分析</h4></li></ol><ul><li>整体分析<br><img src="https://i.loli.net/2020/03/04/WbyeoSvV7dGU4uP.png" alt="compare.png"><br>整体上比上一轮顶会方法效果提升绝对值较大</li><li>段落挑选分析<br><img src="https://i.loli.net/2020/03/04/LTfGYwjOiI9h75M.png" alt="selector_compare.png"><br>加上支撑段落挑选之后最终效果提升有3%~4%,但是在挑选支撑段落上加上MHSA EM可以提升15%+，该方法提升效果还是很明显的，rank的好处:smile:</li><li>GNN实现效果分析<br><img src="https://i.loli.net/2020/03/04/Jg6PvsA4mZj3YXl.png" alt="gnn_compare.png"><br>从实验来看是否从一个段落中的节点边最有效，有问题实体边以及相同实体效果替身不是很明显 :s。整体来看提升1.4%,提升较小，但是同样重点使用GNN的<a href="https://arxiv.org/pdf/1911.03631.pdf" target="_blank" rel="noopener">HGN</a>提升较大,分层GNN赛高<h3 id="细节发现"><a href="#细节发现" class="headerlink" title="细节发现"></a>细节发现</h3></li><li>在进行段落挑选时选用2效果较好，和齐鹏的<a href="https://arxiv.org/pdf/1910.07000.pdf" target="_blank" rel="noopener">GoldEn Retriever</a>定的参数一样:joy:</li><li>在最后预测时答案和答案类型使用的是两层多层感知机，而是否是支撑段落使用的一层感知机。炼丹++ :s<h2 id="开源可复现"><a href="#开源可复现" class="headerlink" title="开源可复现"></a>开源可复现</h2><h3 id="开源地址"><a href="#开源地址" class="headerlink" title="开源地址"></a>开源地址</h3>无<h3 id="复现效果"><a href="#复现效果" class="headerlink" title="复现效果"></a>复现效果</h3>无</li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> 阅读理解 </tag>
            
            <tag> NLP </tag>
            
            <tag> HotpotQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hotpotqa分析</title>
      <link href="/2019/12/09/hotpotqa-fen-xi/"/>
      <url>/2019/12/09/hotpotqa-fen-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="hotpotqa分析"><a href="#hotpotqa分析" class="headerlink" title="hotpotqa分析"></a>hotpotqa分析</h1><h2 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h2><p><a href="https://arxiv.org/pdf/1809.09600.pdf" target="_blank" rel="noopener">HOTPOTQA: A Dataset for Diverse, Explainable<br>Multi-hop Question Answering</a></p><h2 id="简单数据分析"><a href="#简单数据分析" class="headerlink" title="简单数据分析"></a>简单数据分析</h2><h3 id="数据样例"><a href="#数据样例" class="headerlink" title="数据样例"></a>数据样例</h3><p><img src="https://i.loli.net/2019/12/09/Xru7oOWUNjbLk1M.png" alt="数据样例.png"></p><h3 id="答案长度分布"><a href="#答案长度分布" class="headerlink" title="答案长度分布"></a>答案长度分布</h3><p><img src="https://i.loli.net/2019/12/09/Xru7oOWUNjbLk1M.png" alt="答案长度分布.png"></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 阅读理解 </tag>
            
            <tag> 数据集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention详细解析</title>
      <link href="/2019/12/08/attention-xiang-xi-jie-xi/"/>
      <url>/2019/12/08/attention-xiang-xi-jie-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="Attention机制理解"><a href="#Attention机制理解" class="headerlink" title="Attention机制理解"></a>Attention机制理解</h1><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p><a href="https://zhuanlan.zhihu.com/p/47063917" target="_blank" rel="noopener">Attention机制详解（一）——Seq2Seq中的Attention</a></p><h2 id="Attention提出理由"><a href="#Attention提出理由" class="headerlink" title="Attention提出理由"></a>Attention提出理由</h2><h3 id="解决痛点"><a href="#解决痛点" class="headerlink" title="解决痛点"></a>解决痛点</h3><p>在传统的机器翻译中采用encoder-decoder结构，encoder将输入的句子将其转换为定长的向量，然后decoder将向量转化为目标文字。且通常是encoder将最后一层hidden vector作为decoder的起始，然后通过decoder翻译为其他语言。这其中会由于RNN自身特性带来长程梯度消失和并行化差的问题。其中较长的句子也较难在最后的vector中保存需要的有效信息</p><h3 id="提出解决方案"><a href="#提出解决方案" class="headerlink" title="提出解决方案"></a>提出解决方案</h3><p>模拟人翻译的过程，当翻译部分词时将注意力或者更多的注意力放在需要关注的词上，通过类似于赋权的方式计算每个输入位置j与输出位置的关联性。例如可以计算每个输入位置j和当前输出位置的关联性$e_{tj} = a(s_{t-1}, h_j)$,所以写成向量形式就可以得到$\stackrel{-&gt;}{e_t} = (a(s_{t-1}, h_1), …, a(s_{t-1}, h_T))$ $a$是一种相关性的算符，常见的有点乘形式$\stackrel{-&gt;}{e_t}=\stackrel{-&gt;}{s_{t-1}}^T\stackrel{-&gt;}{h}$,加权点乘$\stackrel{-&gt;}{s_{t-1}}^TW\stackrel{-&gt;}{h}$, 加和$\stackrel{-&gt;}{v}^Ttanh(W_1\stackrel{-&gt;}{h} + W_2\stackrel{-&gt;}{s_{t - 1}})$,然后$\stackrel{-&gt;}{s_{t - 1}}$进行softmax操作将normalize得到attention的分布</p><h3 id="self-attention提出原因"><a href="#self-attention提出原因" class="headerlink" title="self-attention提出原因"></a>self-attention提出原因</h3><p>尽可能的去除RNNs网络结构，解决RNN由于其顺序结构进行训练，训练速度会受到约束。在RNN中需要处理对句子中的词一步步地进行顺序处理，并且当它们相距较远时候效果较差。Self-Attention利用了Attention的机制，计算每个单词和其他所有单词之间的关联。可以更好地考虑上下文的信息</p><h3 id="Transformer整体结构解析"><a href="#Transformer整体结构解析" class="headerlink" title="Transformer整体结构解析"></a>Transformer整体结构解析</h3><p>使用Multi-head Attention将多个Self-Attention结构结合，每个head会学习到不同的表征，给模型更大的容量</p><h3 id="Self-Attention详细解析"><a href="#Self-Attention详细解析" class="headerlink" title="Self-Attention详细解析"></a>Self-Attention详细解析</h3><p>Self-Attention基本结构如下<img src="./scaled_dot_product_attention.jpg" alt="avatar"></p><h4 id="对于Self-Attention的利用"><a href="#对于Self-Attention的利用" class="headerlink" title="对于Self-Attention的利用"></a>对于Self-Attention的利用</h4><p>对于Self-Attention来说使用来自一个输入的Q(Query)、K(Key)、V(value)进行计算。首先计算Q与K之间的点乘，然后防止其结果过大，除以一个尺度标度$\sqrt{d_k}$,其中$d_k$为一个query和key向量的维度。再利用Softmax将其结果归一化为概率分布，然后再乘以矩阵V就得到权重求和的表示。该操作表示为$Attention(Q, K, V)=softmax(QK^T\div\sqrt{d_k})V$,其中Q,K,V都是通过输入向量进行矩阵运算得到。有一个可视化较好的<a href="https://zhuanlan.zhihu.com/p/47282410" target="_blank" rel="noopener">解释</a>。需要注意的点是，在类似于encoder和decoder的第一层中q,k,v都是使用来自前一层的decoder的输出，但是在decoder的第二层使用的是来自q是来自encoder的输出，k,v是来自decoder的第一层结果。同时在decoder中使用的不是单纯的Multi-Head Attention而是使用了Masked Multi-Head Attention（因为在翻译过程中不知道后面的输入?)。</p><h4 id="其他结构"><a href="#其他结构" class="headerlink" title="其他结构"></a>其他结构</h4><p>使用了Positional Encoding，该方法主要是将模型没有recurrence和convolution的结构导致没够关于单词在源句子中的位置或绝对的信息，为了让模型更好地学习位置信息的产物，Transformer是使用了三角函数的方式进行encoding。同时在每一步的Multi-Head Attention之后使用了Add和Normanize操作，其中Add表示Residual Connection,该方法是为了解决多层网络训练困难的问题，通过将前一层的信息无差地传递到下一层，可以有效的关注差异部分，这一方法之前在ResNet等图像处理中经常被使用到。而Norm是代表Layer Normalization，该方法通过对层的激活值得归一化，加速模型的训练过程，使得模型可以更快地收敛<a href="https://arxiv.org/pdf/1607.06450.pdf" target="_blank" rel="noopener">Layer Normalization</a></p><h2 id="Attention模型的应用"><a href="#Attention模型的应用" class="headerlink" title="Attention模型的应用"></a>Attention模型的应用</h2><h3 id="自然语言处理"><a href="#自然语言处理" class="headerlink" title="自然语言处理"></a>自然语言处理</h3><h4 id="创造新的结构Universal-Transformers"><a href="#创造新的结构Universal-Transformers" class="headerlink" title="创造新的结构Universal Transformers"></a>创造新的结构Universal Transformers</h4><p><a href="https://arxiv.org/pdf/1807.03819.pdf" target="_blank" rel="noopener">Universal Transformers</a><br><br>该文章结合了Transformer结构和RNN循环归纳的优点，使得Transformer结构能够适用更多自然语言理解的问题。</p><h4 id="创造新的预训练模型Bert等"><a href="#创造新的预训练模型Bert等" class="headerlink" title="创造新的预训练模型Bert等"></a>创造新的预训练模型Bert等</h4><p><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><br><br>使用双向的Transformer进行预处理，得到包含有上下文信息的表征，根据表征可以fine-tune很多自然语言处理任务，对于GLUE Benchmark(主要包含MNLI,RTE：比较两个句子的语义关系，QQP：判别Quora上两个问题相似度，QNLI：问答，SST-2：情感分析，CoLA:语句合理性判别，STS-B, MRPC：句子相似度判别)，SQuAD(问答)，NER（命名实体识别）等都有极大的提高.</p><h4 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h4><p><a href="https://arxiv.org/abs/1801.10198.pdf" target="_blank" rel="noopener">Generating Wikipedia by Summarizing Long Sequences</a></p><h3 id="图像处理及合成"><a href="#图像处理及合成" class="headerlink" title="图像处理及合成"></a>图像处理及合成</h3><h4 id="Attention利用始祖"><a href="#Attention利用始祖" class="headerlink" title="Attention利用始祖"></a>Attention利用始祖</h4><p><a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="noopener">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a><br><br>利用Attention机制进行Image Caption(将图像翻译为文字表述)</p><h4 id="文本合成和超分使用"><a href="#文本合成和超分使用" class="headerlink" title="文本合成和超分使用"></a>文本合成和超分使用</h4><p><a href="https://arxiv.org/abs/1802.05751" target="_blank" rel="noopener">Image Transformer</a><br><br>可以使用Attention机制对图像进行合成，例如将局部图像进行补全，也可以将低分辨率的图像还原高分辨率的图像。同时由于Image Transformer模型训练的稳定性，可能和GAN有抗衡之势</p><h3 id="其他领域结合"><a href="#其他领域结合" class="headerlink" title="其他领域结合"></a>其他领域结合</h3><h4 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h4><p><a href="https://arxiv.org/pdf/1711.04725.pdf" target="_blank" rel="noopener">Neural Attentive Session-based Recommendation</a><br><br>利用Attention模型处理用户sesstion中的序列信息进行相关推荐</p><h4 id="音乐生成"><a href="#音乐生成" class="headerlink" title="音乐生成"></a>音乐生成</h4><p><a href="">Generating Long-Term Structure in Songs and Stories</a><br><br>使用Attention RNN创作乐曲</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
            <tag> BERT </tag>
            
            <tag> 网络结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UNC多粒度支撑段落和支撑句</title>
      <link href="/2019/12/08/unc-duo-li-du-zhi-cheng-duan-luo-he-zhi-cheng-ju/"/>
      <url>/2019/12/08/unc-duo-li-du-zhi-cheng-duan-luo-he-zhi-cheng-ju/</url>
      
        <content type="html"><![CDATA[<h1 id="UNC多粒度支撑段落和支撑句"><a href="#UNC多粒度支撑段落和支撑句" class="headerlink" title="UNC多粒度支撑段落和支撑句"></a>UNC多粒度支撑段落和支撑句</h1><h2 id="论文地址"><a href="#论文地址" class="headerlink" title="论文地址"></a>论文地址</h2><p><a href="https://arxiv.org/pdf/1909.08041.pdf" target="_blank" rel="noopener">Revealing the Importance of Semantic Retrieval<br>for Machine Reading at Scale</a></p><h2 id="一句话概括"><a href="#一句话概括" class="headerlink" title="一句话概括"></a>一句话概括</h2><p>通过term按照文本相关性搜索到可靠数量的段落，然后通过神经网络模型召回支撑段落，然后再在支撑段落里召回支撑句，并且文章做了大量的消融实验证明了支撑段落具有重大意义，支撑句需要有一些噪音效果才比较好。</p><h2 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h2 id="开源可复现"><a href="#开源可复现" class="headerlink" title="开源可复现"></a>开源可复现</h2><p>开源</p><h3 id="开源地址"><a href="#开源地址" class="headerlink" title="开源地址"></a>开源地址</h3><p><a href="easonnie/semanticRetrievalMRS">easonnie/semanticRetrievalMRS</a></p><h3 id="复现效果"><a href="#复现效果" class="headerlink" title="复现效果"></a>复现效果</h3><p>无</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> IR </tag>
            
            <tag> 信息检索 </tag>
            
            <tag> hotpotqa </tag>
            
            <tag> emnlp </tag>
            
            <tag> 2019 </tag>
            
            <tag> multi-hot </tag>
            
            <tag> 消融实验 </tag>
            
            <tag> 需要精读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微软实验室HGN分层图网络</title>
      <link href="/2019/12/08/wei-ruan-shi-yan-shi-hgn-fen-ceng-tu-wang-luo/"/>
      <url>/2019/12/08/wei-ruan-shi-yan-shi-hgn-fen-ceng-tu-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="微软实验室HGN分层图网络"><a href="#微软实验室HGN分层图网络" class="headerlink" title="微软实验室HGN分层图网络"></a>微软实验室HGN分层图网络</h1><h2 id="论文地址"><a href="#论文地址" class="headerlink" title="论文地址"></a>论文地址</h2><p><a href="https://arxiv.org/pdf/1911.03631.pdf" target="_blank" rel="noopener">Hierarchical Graph Network for Multi-hop Question Answering</a></p><h2 id="一句话概括"><a href="#一句话概括" class="headerlink" title="一句话概括"></a>一句话概括</h2><p>使用图神经网络实现段落、句子、实体关联加入到多步问答中，做了大量消融实验，包含各个层之间的消融以及不同预训练模型的消融</p><h2 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h2 id="开源可复现"><a href="#开源可复现" class="headerlink" title="开源可复现"></a>开源可复现</h2><p>非开源</p><h3 id="开源地址"><a href="#开源地址" class="headerlink" title="开源地址"></a>开源地址</h3><p>无</p><h3 id="复现效果"><a href="#复现效果" class="headerlink" title="复现效果"></a>复现效果</h3><p>无</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 阅读理解 </tag>
            
            <tag> 图神经网络 </tag>
            
            <tag> 多层图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客搭建</title>
      <link href="/2019/12/08/blog-builder/"/>
      <url>/2019/12/08/blog-builder/</url>
      
        <content type="html"><![CDATA[<h1 id="博客搭建"><a href="#博客搭建" class="headerlink" title="博客搭建"></a>博客搭建</h1><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://godweiyang.com/about/" target="_blank" rel="noopener">韦阳的博客</a></p><h2 id="实际使用主题"><a href="#实际使用主题" class="headerlink" title="实际使用主题"></a>实际使用主题</h2><p><a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">hexo-theme-matery</a></p><h2 id="主题目前特色实现功能"><a href="#主题目前特色实现功能" class="headerlink" title="主题目前特色实现功能"></a>主题目前特色实现功能</h2><ul><li>标签和分类</li><li>文档搜索</li><li>gittalk集成</li></ul>]]></content>
      
      
      <categories>
          
          <category> 实用技巧 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>斯坦福NLP齐鹏多步问题生成实现hotpotqa开放域问答</title>
      <link href="/2019/12/08/si-tan-fu-nlp-qi-peng-duo-bu-wen-ti-sheng-cheng-shi-xian-hotpotqa-kai-fang-yu-wen-da/"/>
      <url>/2019/12/08/si-tan-fu-nlp-qi-peng-duo-bu-wen-ti-sheng-cheng-shi-xian-hotpotqa-kai-fang-yu-wen-da/</url>
      
        <content type="html"><![CDATA[<h1 id="斯坦福NLP齐鹏多步问题生成实现hotpotqa开放域问答"><a href="#斯坦福NLP齐鹏多步问题生成实现hotpotqa开放域问答" class="headerlink" title="斯坦福NLP齐鹏多步问题生成实现hotpotqa开放域问答"></a>斯坦福NLP齐鹏多步问题生成实现hotpotqa开放域问答</h1><h2 id="论文地址"><a href="#论文地址" class="headerlink" title="论文地址"></a>论文地址</h2><p><a href="https://arxiv.org/pdf/1910.07000.pdf" target="_blank" rel="noopener">Answering Complex Open-domain Questions Through Iterative Query Generation</a></p><h2 id="一句话概括"><a href="#一句话概括" class="headerlink" title="一句话概括"></a>一句话概括</h2><p>使用启发式的方法进行多步问题的细粒度化，在召回量较少的情况下得到高准确率的支撑文档，进而提高开放域问答的效果，并完成一个完整的Pipeline的工作,其中包含很多小技巧，包含在Content和question编码的时候使用0、1而不是cls/sep，提高实验基线。</p><h2 id="论文精读"><a href="#论文精读" class="headerlink" title="论文精读"></a>论文精读</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h2 id="开源可复现"><a href="#开源可复现" class="headerlink" title="开源可复现"></a>开源可复现</h2><h3 id="开源地址"><a href="#开源地址" class="headerlink" title="开源地址"></a>开源地址</h3><p><a href="https://github.com/qipeng/golden-retriever" target="_blank" rel="noopener">golden-retriever</a></p><h3 id="复现效果"><a href="#复现效果" class="headerlink" title="复现效果"></a>复现效果</h3><p>暂无</p><h2 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h2><p>hotpotqa 开放域 问答 问题生成 多步 EMNLP2019</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 阅读理解 </tag>
            
            <tag> 个人论文理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>404</title>
      <link href="/1970/01/01/404/"/>
      <url>/1970/01/01/404/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
